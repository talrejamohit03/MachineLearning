{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING LAB ASSIGNMENT\n",
    "\n",
    "\n",
    "# PERCEPTRON LEARNING ALGORITHM\n",
    "\n",
    "\n",
    "### NAME     : **MOHIT TALREJA**\n",
    "\n",
    "### ROLL NO. : **177237**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function predict takes two parameters:\n",
    "\n",
    "- the weights array $w_{0},w_{1},...,w_{n}$ , here, n=number of features\n",
    "- features array for a single row in the dataset, each entry being of the form $x_{0},x_{1},...,x_{n}$.\n",
    "\n",
    "The function computes the equation,\n",
    "\n",
    "$\\sum_{i=0}^{n}w_{i}.x_{i}$\n",
    "\n",
    "where $x_{0} = 1$, \n",
    "\n",
    "This is the scalar dot product of the 2 vectors, weights and features.\n",
    "\n",
    "If this value is greater than 0, then perceptron should predict the output to be 1, otherwise 0.\n",
    "It returns this prediction to the function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(weights,features):\n",
    "    \n",
    "    summation = np.dot(weights,features.transpose()) #scalar dot product\n",
    "\n",
    "    if(summation>0):\n",
    "        prediction = 1\n",
    "    else:\n",
    "        prediction = 0\n",
    "    \n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perceptronTrain function below takes 4 parameters:\n",
    "- features: the 2d features array containing all data points and their feature values(the first column must be filled with 1s)\n",
    "- labels: the observed/actual values from the dataset\n",
    "- num_iter: number of epochs for which the training algorithm is to be run\n",
    "- l_rate: learning rate hyperparameter\n",
    "\n",
    "It first initializes the weights to 0. The size of the array will be equal to the number of features (first column of the passed features array has all entries as 1, so it is actually number of features in the dataset + 1).\n",
    "In each iteration, it will iterate through all the rows in the dataset. It calls the predict function above to get the predicted value of the label.\n",
    "\n",
    "If the observed value is the same as the predicted value, then weights will remain the same.\n",
    "Else, weights will be updated as per the equation \n",
    "\n",
    "$w_{i} = w_{i} + \\alpha.(observed - predicted).x_{i}$\n",
    "\n",
    "$\\alpha$ = learning rate hyperparameter value\n",
    "\n",
    "The function returns the weights array to the function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptronTrain(features,labels,num_iter,l_rate):\n",
    "    \n",
    "    weights = np.zeros(shape=(1,features.shape[1])) #initializing weights array to 0s\n",
    "  \n",
    "    for epoch in range(num_iter):\n",
    "        \n",
    "        for i in range(len(features)):\n",
    "            \n",
    "            prediction = predict(weights,features.iloc[i,:]) #prediction for current row\n",
    "            \n",
    "            weights += l_rate *(labels[i]-prediction)*features.iloc[i,:] #updating weights' values\n",
    "        \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset:**\n",
    "Prediction of breast cancer whether it is Malignant or Benign\n",
    "\n",
    "Multivariate dataset that has 32 attributes\n",
    "1. ID number\n",
    "2. Diagnosis (M = malignant, B = benign) -> Output Label\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus:\n",
    "\n",
    "1. radius (mean of distances from center to points on the perimeter)\n",
    "2. texture (standard deviation of gray-scale values)\n",
    "3. perimeter\n",
    "4. area\n",
    "5. smoothness (local variation in radius lengths)\n",
    "6. compactness (perimeter^2 / area - 1.0)\n",
    "7. concavity (severity of concave portions of the contour)\n",
    "8. concave points (number of concave portions of the contour)\n",
    "9. symmetry\n",
    "10. fractal dimension (\"coastline approximation\" - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           0  1      2      3       4       5        6        7        8   \\\n",
      "0      842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.30010   \n",
      "1      842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.08690   \n",
      "2    84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.19740   \n",
      "3    84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.24140   \n",
      "4    84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.19800   \n",
      "..        ... ..    ...    ...     ...     ...      ...      ...      ...   \n",
      "564    926424  M  21.56  22.39  142.00  1479.0  0.11100  0.11590  0.24390   \n",
      "565    926682  M  20.13  28.25  131.20  1261.0  0.09780  0.10340  0.14400   \n",
      "566    926954  M  16.60  28.08  108.30   858.1  0.08455  0.10230  0.09251   \n",
      "567    927241  M  20.60  29.33  140.10  1265.0  0.11780  0.27700  0.35140   \n",
      "568     92751  B   7.76  24.54   47.92   181.0  0.05263  0.04362  0.00000   \n",
      "\n",
      "          9   ...      22     23      24      25       26       27      28  \\\n",
      "0    0.14710  ...  25.380  17.33  184.60  2019.0  0.16220  0.66560  0.7119   \n",
      "1    0.07017  ...  24.990  23.41  158.80  1956.0  0.12380  0.18660  0.2416   \n",
      "2    0.12790  ...  23.570  25.53  152.50  1709.0  0.14440  0.42450  0.4504   \n",
      "3    0.10520  ...  14.910  26.50   98.87   567.7  0.20980  0.86630  0.6869   \n",
      "4    0.10430  ...  22.540  16.67  152.20  1575.0  0.13740  0.20500  0.4000   \n",
      "..       ...  ...     ...    ...     ...     ...      ...      ...     ...   \n",
      "564  0.13890  ...  25.450  26.40  166.10  2027.0  0.14100  0.21130  0.4107   \n",
      "565  0.09791  ...  23.690  38.25  155.00  1731.0  0.11660  0.19220  0.3215   \n",
      "566  0.05302  ...  18.980  34.12  126.70  1124.0  0.11390  0.30940  0.3403   \n",
      "567  0.15200  ...  25.740  39.42  184.60  1821.0  0.16500  0.86810  0.9387   \n",
      "568  0.00000  ...   9.456  30.37   59.16   268.6  0.08996  0.06444  0.0000   \n",
      "\n",
      "         29      30       31  \n",
      "0    0.2654  0.4601  0.11890  \n",
      "1    0.1860  0.2750  0.08902  \n",
      "2    0.2430  0.3613  0.08758  \n",
      "3    0.2575  0.6638  0.17300  \n",
      "4    0.1625  0.2364  0.07678  \n",
      "..      ...     ...      ...  \n",
      "564  0.2216  0.2060  0.07115  \n",
      "565  0.1628  0.2572  0.06637  \n",
      "566  0.1418  0.2218  0.07820  \n",
      "567  0.2650  0.4087  0.12400  \n",
      "568  0.0000  0.2871  0.07039  \n",
      "\n",
      "[569 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data', \n",
    "                   header = None)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Excluding the first 2 columns in feature vector as 1st column is ID number and 2nd column is the output label.\n",
    "Output labels are str type, converting them to boolean values 1 for Malignant(M) and 0 for Benign(B)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.iloc[:,2:] \n",
    "X.insert(0,0,1) #Setting 1st column to 1s, i.e, setting x0 in equation to 1\n",
    "y = data.iloc[:,1] #Output labels are as M,B string values\n",
    "y_ = [] #making new output labels as 1 or 0\n",
    "for label in y:\n",
    "    if(label == \"M\"):\n",
    "        y_.append(1) #1 for Malignant\n",
    "    else:\n",
    "        y_.append(0) #0 for Benign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the dataset into training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_, test_size=0.33,random_state =  37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 10\n",
    "LEARNING_RATE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights = [[-2.08000000e+01 -1.59473100e+02 -2.19784000e+02 -9.45762000e+02\n",
      "  -4.80850000e+02 -1.63770100e+00 -3.11770000e-02  2.04005136e+00\n",
      "   9.10722400e-01 -2.90724000e+00 -1.21831700e+00  1.06301000e+00\n",
      "  -1.24839200e+01  1.27810700e+01  4.99344600e+02 -1.10695700e-01\n",
      "   1.23814000e-02  1.12388160e-01  5.87200000e-04 -2.53417600e-01\n",
      "  -2.08378400e-02 -1.65009900e+02 -3.10077000e+02 -9.68398000e+02\n",
      "   6.05600000e+02 -2.19636800e+00  1.31220000e-01  2.45681190e+00\n",
      "   6.04858000e-01 -4.31158000e+00 -1.31520100e+00]]\n"
     ]
    }
   ],
   "source": [
    "#calling perceptron training algorithm to get learned weights \n",
    "w = perceptronTrain(X_train,y_train,NUM_EPOCHS,LEARNING_RATE)\n",
    "print(\"Weights = \", end='')\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Prediction Metrics on Test Data\n",
    "\n",
    "Generating the number of correctly predicted output labels on test data and then calculating the accuracy of the model as\n",
    "\n",
    "\n",
    "100*(Number of correctly predicted outputs of Test Data)/(Size of Test Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly predicted 175 out of 188\n",
      "Accuracy = 93.08510638297872\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = 0\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    #getting prediction for corresponding test data values from the learned model\n",
    "    prediction = predict(w,X_test.iloc[i,:])\n",
    "    \n",
    "    if(prediction == y_test[i]):\n",
    "        #if predicted value is the same as observed, it is a correct prediction\n",
    "        correct_predictions+=1; \n",
    "\n",
    "print(\"Correctly predicted \"+str(correct_predictions)+\" out of \"+str(len(y_test)))\n",
    "print(\"Accuracy = \"+str(100*correct_predictions/len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perceptron Learning Algorithm on Logic Gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights for AND logic perceptron: \n",
      "[[-0.2  0.2  0.1]]\n",
      "Weights for OR logic perceptron: \n",
      "[[0.  0.1 0.1]]\n"
     ]
    }
   ],
   "source": [
    "X_LOGIC = pd.DataFrame([[1,0,0],[1,0,1],[1,1,0],[1,1,1]])\n",
    "Y_AND = [0,0,0,1] #output labels for AND gate\n",
    "Y_OR = [0,1,1,1] #output labels for OR gate\n",
    "\n",
    "#training on inputs\n",
    "weights_AND = perceptronTrain(X_LOGIC,Y_AND,10,0.1)\n",
    "weights_OR = perceptronTrain(X_LOGIC,Y_OR,10,0.1)\n",
    "\n",
    "print(\"Weights for AND logic perceptron: \")\n",
    "print(weights_AND)\n",
    "print(\"Weights for OR logic perceptron: \")\n",
    "print(weights_OR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AND LOGIC perceptron\n",
      "\n",
      " 0  0 output = 0\n",
      " 0  1 output = 0\n",
      " 1  0 output = 0\n",
      " 1  1 output = 1\n"
     ]
    }
   ],
   "source": [
    "print('AND LOGIC perceptron\\n')\n",
    "for i in range(len(X_LOGIC)):\n",
    "    prediction = predict(weights_AND,X_LOGIC.iloc[i,:])\n",
    "    print(X_LOGIC.iloc[[i],[1,2]].to_string(index=False,header=False),end = ' output = ')\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR LOGIC perceptron\n",
      "\n",
      " 0  0 output = 0\n",
      " 0  1 output = 1\n",
      " 1  0 output = 1\n",
      " 1  1 output = 1\n"
     ]
    }
   ],
   "source": [
    "print('OR LOGIC perceptron\\n')\n",
    "for i in range(len(X_LOGIC)):\n",
    "    prediction = predict(weights_OR,X_LOGIC.iloc[i,:])\n",
    "    print(X_LOGIC.iloc[[i],[1,2]].to_string(index=False,header=False),end = ' output = ')\n",
    "    print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
