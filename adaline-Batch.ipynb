{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MACHINE LEARNING LAB ASSIGNMENT\n",
    "\n",
    "\n",
    "# ADALINE LEARNING ALGORITHM\n",
    "\n",
    "\n",
    "### NAME     : **MOHIT TALREJA**\n",
    "\n",
    "### ROLL NO. : **177237**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function predict takes two parameters:\n",
    "\n",
    "- the weights array $w_{0},w_{1},...,w_{n}$ , here, n=number of features\n",
    "- features array for a single row in the dataset, each entry being of the form $x_{0},x_{1},...,x_{n}$.\n",
    "\n",
    "The function computes the weighted sum according to the equation:\n",
    "\n",
    "$\\sum_{i=0}^{n}w_{i}.x_{i}$\n",
    "\n",
    "where $x_{0} = 1$, \n",
    "\n",
    "This is the scalar dot product of the 2 vectors, weights and features.\n",
    "\n",
    "Since the activation function in Adaline is f(x) = x, the function returns the computed weighted sum to the function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(weights,features):\n",
    "    \n",
    "    return np.dot(weights,features.transpose()) #scalar dot product"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adalineTrain function below takes 4 parameters:\n",
    "- features: the 2d features array containing all data points and their feature values(the first column must be filled with 1s)\n",
    "- labels: the observed/actual values from the dataset\n",
    "- num_iter: number of epochs for which the training algorithm is to be run\n",
    "- l_rate: learning rate hyperparameter\n",
    "\n",
    "It first initializes the weights to random values. The size of the array will be equal to the number of features (first column of the passed features array has all entries as 1, so it is actually number of features in the dataset + 1).\n",
    "In each iteration, it will iterate through all the rows in the dataset. It calls the predict function above to get the weighted sum value.\n",
    "\n",
    "The weights are then updated according to the equation: \n",
    "\n",
    "$w_{i} = w_{i} + \\alpha.(observed - predicted).x_{i}$\n",
    "\n",
    "$\\alpha$ = learning rate hyperparameter value\n",
    "\n",
    "The function returns the weights array to the function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adalineTrain(features,labels,num_iter,l_rate):\n",
    "    \n",
    "    weights = np.full(features.shape[1],0.4) #initializing weights array\n",
    "  \n",
    "    for epoch in range(num_iter):\n",
    "        delta_w = np.zeros(features.shape[1])\n",
    "        for i in range(len(features)):\n",
    "            \n",
    "            prediction = predict(weights,features[i]) #prediction for current row\n",
    "            print(\"Train ex = \",features[i],\"prediction = \",prediction)\n",
    "            delta_w += (l_rate *(labels[i]-prediction)*features[i]) #updating weights' values\n",
    "            print(\"after Train example \",i,\"delta w is \",delta_w)\n",
    "        weights+=delta_w\n",
    "        print(\"Iteration \",epoch,weights)\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Dataset\n",
    "\n",
    "Real Estate Valuation dataset\n",
    "\n",
    "The Adaline learning algorithm can be used on a continuous valued dataset.\n",
    "\n",
    "\n",
    "Multivariate dataset that has 7 attributes\n",
    "\n",
    "The inputs are as follows\n",
    "1. X1=the transaction date (for example, 2013.250=2013 March, 2013.500=2013 June, etc.)\n",
    "2. X2=the house age (unit: year)\n",
    "3. X3=the distance to the nearest MRT station (unit: meter)\n",
    "4. X4=the number of convenience stores in the living circle on foot (integer)\n",
    "5. X5=the geographic coordinate, latitude. (unit: degree)\n",
    "6. X6=the geographic coordinate, longitude. (unit: degree)\n",
    "\n",
    "The output label is\n",
    "**Y= house price of unit area (10000 New Taiwan Dollar/Ping, where Ping is a local unit, 1 Ping = 3.3 meter squared)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_excel('https://archive.ics.uci.edu/ml/machine-learning-databases/00477/\\\n",
    "# Real%20estate%20valuation%20data%20set.xlsx')\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "\n",
    "Applying min-max normalization to the column values and converting the DataFrame to a numpy array.\n",
    "\n",
    "The equation used for Min-Max Normalization technique is as follows:\n",
    "\n",
    "$x_{new} = (x_{old} - x_{min})/(x_{max}-x_{min})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=(data-data.min())/(data.max()-data.min()) \n",
    "# data = pd.DataFrame.to_numpy(data)\n",
    "# print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping the first column as that is just an ID number. Adding a column containing 1s at the 0th index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = data[:,1:-1] \n",
    "\n",
    "# #Setting 1st column to 1s, i.e, setting x0 in equation of weighted sum to 1\n",
    "# X = np.insert(X,0,np.ones(X.shape[0]),axis=1) \n",
    "\n",
    "# y = data[:,-1] #Output label values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Splitting the dataset into training and testing\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,random_state =  37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NUM_EPOCHS = 100\n",
    "# LEARNING_RATE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #calling adaline training algorithm to get learned weights \n",
    "# w = adalineTrain(X_train,y_train,NUM_EPOCHS,LEARNING_RATE)\n",
    "# print(\"Weights = \", end='')\n",
    "# print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Prediction Metrics on Test Data\n",
    "\n",
    "Comparing the predicted output with the actual output on test data. If the model predicts the output with a relative absolute error of 0.3 dollars, it is deemed to be correctly predicted. \n",
    "\n",
    "Calculating the accuracy of the model as\n",
    "\n",
    "\n",
    "100*(Number of correctly predicted outputs of Test Data)/(Size of Test Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_predictions = 0\n",
    "\n",
    "# for i in range(len(y_test)):\n",
    "#     #getting prediction for corresponding test data values from the learned model\n",
    "#     prediction = predict(w,X_test[i])\n",
    "    \n",
    "#     if(abs(prediction - y_test[i])<=0.3):\n",
    "#         correct_predictions+=1; \n",
    "\n",
    "# print(\"Correctly predicted to an accuracy of 0.3 dollars \"+str(correct_predictions)+\" out of \"+str(len(y_test)))\n",
    "# print(\"Accuracy = \"+str(100*correct_predictions/len(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaline Learning Algorithm on Logic Gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ex =  [1 0 0] prediction =  0.4\n",
      "after Train example  0 delta w is  [0.12 0.   0.  ]\n",
      "Train ex =  [1 0 1] prediction =  0.8\n",
      "after Train example  1 delta w is  [-0.04  0.   -0.16]\n",
      "Train ex =  [1 1 0] prediction =  0.8\n",
      "after Train example  2 delta w is  [-0.2  -0.16 -0.16]\n",
      "Train ex =  [1 1 1] prediction =  1.2000000000000002\n",
      "after Train example  3 delta w is  [-0.24 -0.2  -0.2 ]\n",
      "Iteration  0 [0.16 0.2  0.2 ]\n",
      "Train ex =  [1 0 0] prediction =  0.15999999999999992\n",
      "after Train example  0 delta w is  [0.168 0.    0.   ]\n",
      "Train ex =  [1 0 1] prediction =  0.3599999999999999\n",
      "after Train example  1 delta w is  [ 0.096  0.    -0.072]\n",
      "Train ex =  [1 1 0] prediction =  0.3599999999999999\n",
      "after Train example  2 delta w is  [ 0.024 -0.072 -0.072]\n",
      "Train ex =  [1 1 1] prediction =  0.5599999999999998\n",
      "after Train example  3 delta w is  [0.112 0.016 0.016]\n",
      "Iteration  1 [0.272 0.216 0.216]\n",
      "Weights for OR logic adaline: \n",
      "[0.272 0.216 0.216]\n"
     ]
    }
   ],
   "source": [
    "X_LOGIC = np.array([[1,0,0],[1,0,1],[1,1,0],[1,1,1]])\n",
    "\n",
    "Y_AND = np.array([0,0,0,1]) #output labels for AND gate\n",
    "\n",
    "Y_OR = np.array([1,0,0,1]) #output labels for OR gate\n",
    "\n",
    "\n",
    "#training on inputs\n",
    "# weights_AND = adalineTrain(X_LOGIC,Y_AND,2,0.1)\n",
    "weights_OR = adalineTrain(X_LOGIC,Y_OR,2,0.2)\n",
    "\n",
    "# print(\"Weights for AND logic adaline: \")\n",
    "# print(weights_AND)\n",
    "print(\"Weights for OR logic adaline: \")\n",
    "print(weights_OR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print('AND LOGIC Adaline\\n')\n",
    "# for i in range(len(X_LOGIC)):\n",
    "#     prediction = predict(weights_AND,X_LOGIC[i])\n",
    "#     print(X_LOGIC[[i],[1,2]],end = ' output = ')\n",
    "#     print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR LOGIC Adaline\n",
      "\n",
      "[0 0] output = 0.272\n",
      "[0 1] output = 0.48800000000000004\n",
      "[1 0] output = 0.48800000000000004\n",
      "[1 1] output = 0.7040000000000001\n"
     ]
    }
   ],
   "source": [
    "print('OR LOGIC Adaline\\n')\n",
    "for i in range(len(X_LOGIC)):\n",
    "    prediction = predict(weights_OR,X_LOGIC[i])\n",
    "    print(X_LOGIC[[i],[1,2]],end = ' output = ')\n",
    "    print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
